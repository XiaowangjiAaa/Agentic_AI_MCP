from openai import OpenAI
from dotenv import load_dotenv
from agent.executor import execute_plan
from tools.path_utils import (
    get_test_image_paths,
    generate_segment_plan_from_paths,
    get_test_image_by_index,
    list_image_paths
)
from agent.visualize_tools import visualize_crack_result
from agent.gpt_intent_parser import classify_intent
from agent.object_memory_manager import ObjectMemoryManager
from agent.session_manager import SessionManager
import os

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# === åˆå§‹åŒ– Session ç®¡ç†å™¨ ===
session = SessionManager()
logger = session.get_logger()
memory = session.get_memory()
object_store = ObjectMemoryManager()

def chat_fallback(user_input: str) -> str:
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“æ³¨äºè£‚ç¼å›¾åƒåˆ†æçš„ AI Agentã€‚"},
            {"role": "user", "content": user_input}
        ]
    )
    reply = response.choices[0].message.content.strip()
    logger.log_agent(reply)
    return reply

def normalize(s: str) -> str:
    return s.lower().replace(" ", "").replace("_", "").replace("(", "").replace(")", "")

def match_metric_key(requested: str, candidate: str) -> bool:
    return normalize(requested) in normalize(candidate)

METRIC_ALIASES = {
    "maxwidth": "max_width",
    "maximumwidth": "max_width",
    "avgwidth": "avg_width",
    "averagewidth": "avg_width",
    "meanwidth": "avg_width",
    "length": "length",
    "area": "area"
}

def map_to_standard_metric(name: str) -> str:
    key = normalize(name)
    return METRIC_ALIASES.get(key, key)

if __name__ == "__main__":
    while True:
        user_input = input("\nğŸ§  è¯·è¾“å…¥è‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼ˆæˆ– exitï¼‰: ")
        if user_input.strip().lower() in {"exit", "quit"}:
            session.export_memory_snapshot()
            session.print_summary()
            break

        logger.log_user(user_input)
        print("ğŸ§­ æ­£åœ¨ç†è§£æ„å›¾...")
        intent_info = classify_intent(user_input)
        intent = intent_info["intent"]
        indices = intent_info.get("target_indices", [])
        pixel_size = intent_info.get("pixel_size_mm", 0.5)

        raw_metrics = intent_info.get("metrics", [])
        metrics = [map_to_standard_metric(m) for m in raw_metrics]
        if not metrics:
            metrics = ["length", "area", "max_width", "avg_width"]

        visual_types = intent_info.get("visual_types") or ["mask"]
        print(f"[DEBUG] ä½¿ç”¨çš„ visual_types: {visual_types}")

        if intent == "chat":
            reply = chat_fallback(user_input)
            print("ğŸ’¬", reply)
            continue

        if intent == "visualize":
            if not indices:
                print("âš ï¸ æœªæŒ‡å®šå¯è§†åŒ–å›¾åƒç´¢å¼•")
                continue
            for i in indices:
                name = os.path.basename(get_test_image_by_index(i)).replace(".jpg", "").replace(".png", "").replace(".jpeg", "")
                visualize_crack_result(subject_name=name, memory=memory, visual_types=visual_types)
            continue

        print(f"ğŸ§­ è¯†åˆ«åˆ°æ„å›¾: {intent} | å›¾åƒç´¢å¼•: {indices} | åƒç´ å°ºå¯¸: {pixel_size} mm/pixel | æŒ‡æ ‡: {metrics}")
        logger.log_agent(f"è¯†åˆ«åˆ°æ„å›¾: {intent} | å›¾åƒç´¢å¼•: {indices} | åƒç´ å°ºå¯¸: {pixel_size} mm/pixel | æŒ‡æ ‡: {metrics}")

        plan = []
        all_images = get_test_image_paths()
        index_to_image_name = {
            i: os.path.basename(p).replace(".jpg", "").replace(".png", "").replace(".jpeg", "")
            for i, p in enumerate(all_images)
        }

        if intent == "segment":
            image_paths = all_images if not indices else [get_test_image_by_index(i) for i in indices]
            for img_path in image_paths:
                object_store.register_image(img_path)
            plan = generate_segment_plan_from_paths(image_paths)

        elif intent == "quantify":
            image_paths = all_images if not indices else [get_test_image_by_index(i) for i in indices]
            if not indices:
                indices = list(range(len(image_paths)))

            all_satisfied = True
            for i in indices:
                name = index_to_image_name[i]
                if not memory.has_metrics(name, metrics, pixel_size):
                    all_satisfied = False
                    break

            if all_satisfied:
                log_msg = []
                for i in indices:
                    name = index_to_image_name[i]
                    stored = memory.get_metrics_by_name(name, pixel_size)
                    result_lines = [f"  ğŸ”¹ {name}"]
                    for m in metrics:
                        found = False
                        for k, v in stored.items():
                            if match_metric_key(m, k):
                                result_lines.append(f"     {k}: {v}")
                                found = True
                        if not found:
                            result_lines.append(f"     âš ï¸ æœªæ‰¾åˆ°æŒ‡æ ‡: {m}")
                    log_msg.extend(result_lines)
                agent_reply = "\n".join(["ğŸ“‹ æ‰€è¯·æ±‚å›¾åƒæŒ‡æ ‡å·²åœ¨è®°å¿†ä¸­ï¼Œç›´æ¥è¯»å–:"] + log_msg)
                print(agent_reply)
                logger.log_agent(agent_reply)
                continue

            for i, img_path in zip(indices, image_paths):
                name = index_to_image_name[i]
                object_store.register_image(img_path)
                mask_name = os.path.basename(img_path).replace(".jpg", ".png").replace(".jpeg", ".png")
                mask_path = os.path.join("outputs/masks", mask_name)
                if not os.path.exists(mask_path):
                    print(f"ğŸ” æ©è†œä¸å­˜åœ¨ï¼Œæ’å…¥ segment ä»»åŠ¡: {mask_path}")
                    plan.append({"tool": "segment_crack_image", "args": {"image_path": img_path}})
                plan.append({
                    "tool": "quantify_crack_geometry",
                    "args": {
                        "mask_path": mask_path,
                        "pixel_size_mm": pixel_size,
                        "metrics": metrics,
                        "visuals": ["skeleton", "max_width"]
                    },
                    "subject": name
                })

        elif intent == "compare":
            plan = [{
                "tool": "compare_results_csv",
                "args": {
                    "gt_csv_path": "outputs/results/ground_truth.csv",
                    "pred_csv_path": "outputs/results/prediction.csv"
                }
            }]

        elif intent == "plot":
            plan = [{
                "tool": "plot_comparison_graphs",
                "args": {
                    "gt_csv_path": "outputs/results/ground_truth.csv",
                    "pred_csv_path": "outputs/results/prediction.csv"
                }
            }]

        if not plan:
            print("âš ï¸ æ— æ³•ç”Ÿæˆå·¥å…·é“¾è®¡åˆ’")
            logger.log_agent("âš ï¸ æ— æ³•ç”Ÿæˆå·¥å…·é“¾è®¡åˆ’")
            continue

        print("\nğŸ“‹ å·¥å…·é“¾æ‰§è¡Œè®¡åˆ’:")
        for step in plan:
            print(f"â†’ {step['tool']}({step['args']})")

        print("\nğŸš€ æ‰§è¡Œä¸­...")
        results = execute_plan(plan, memory=memory)

        print("\nâœ… æ‰§è¡Œç»“æœ:")
        quantify_steps = [step for step in plan if step["tool"] == "quantify_crack_geometry"]
        for i, r in enumerate(results):
            tool = r['tool']
            status = r['status']
            summary = r['summary']
            print(f"[{tool}] â†’ {status}")

            if tool == "quantify_crack_geometry":
                outputs = r.get("outputs", {})
                if outputs and len(quantify_steps) == 1:
                    print("ğŸ“Š è¯·æ±‚æŒ‡æ ‡:")
                    for m in metrics:
                        matched = False
                        for k, v in outputs.items():
                            if match_metric_key(m, k):
                                print(f"  {k}: {v}")
                                matched = True
                        if not matched:
                            print(f"  âš ï¸ æœªåŒ¹é…åˆ°æŒ‡æ ‡: {m}")
                elif len(quantify_steps) == 1:
                    print(f"ğŸ“Š {summary}")

        for i, step in enumerate(plan):
            if step["tool"] == "quantify_crack_geometry":
                subject = step.get("subject", f"image_{i}")
                results[i]["subject"] = subject

        memory.update_context(intent, indices, pixel_size, results, plan)
        logger.log_agent_structured({
            "intent": intent,
            "images": [index_to_image_name[i] for i in indices],
            "pixel_size": pixel_size,
            "metrics": metrics,
            "plan": plan,
            "result": results,
            "message": "âœ… æ‰§è¡Œå®Œæˆã€‚"
        })
